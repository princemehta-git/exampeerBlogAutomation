# Exampeer Blog Automation ğŸ¤–ğŸ“

**Exampeer Blog Automation** is a Python-based tool designed to automate the process of scraping data from a DOCX file, parsing it, converting it into an Excel file, and uploading the data to the Exampeer website on a daily basis. This tool helps streamline the content posting process for Exampeer's blog.

---

## ğŸ§° Features

- ğŸ“„ Scrapes data from DOCX files and converts it into an **Excel sheet**  
- ğŸ“Š Automatically uploads the parsed data to the **Exampeer website**  
- ğŸ•’ Automates daily operations for blog content management  
- ğŸ’» Handles error notifications with clear images and icons  
- ğŸ“ Generates detailed reports in `report.xlsx`

---

## ğŸ“ Project Structure

ExampeerBlogAutomation/  
â”‚  
â”œâ”€â”€ PostBlog.py            # Main script to scrape and upload blog data  
â”œâ”€â”€ analysed.xlsx          # Excel file with parsed blog data  
â”œâ”€â”€ autoAnalyser.txt       # Text file for analyzing the data  
â”œâ”€â”€ autoDetector.txt       # File used for detecting relevant data  
â”œâ”€â”€ autoUploader.txt       # Contains credentials and settings for auto-upload  
â”œâ”€â”€ bg.png                 # Background image for notifications  
â”œâ”€â”€ error.ico              # Error icon for notifications  
â”œâ”€â”€ error.jpg              # Error image for notifications  
â”œâ”€â”€ icon.ico               # App icon for UI or notifications  
â”œâ”€â”€ notification.jpg       # Notification image shown during processes  
â”œâ”€â”€ report.xlsx            # Excel report generated after parsing and upload  
â”œâ”€â”€ rough.py               # Script for testing or debugging  
â”œâ”€â”€ rough2.py              # Another testing script  
â”œâ”€â”€ sample.xlsx            # Sample input Excel file for testing  
â”œâ”€â”€ showBrowser.txt        # Configuration for showing browser during upload  
â”œâ”€â”€ temp.txt               # Temporary file for intermediate data  
â””â”€â”€ README.md              # Project documentation (this file)

---

## ğŸ› ï¸ Requirements

- Python 3.7+  
- python-docx  
- pandas  
- requests  
- selenium (if using browser automation)  

Install dependencies:
``` bash
  pip install python-docx pandas requests selenium
```
## ğŸ–¥ï¸ How to Use

1. Place your **DOCX file** with blog content in the working directory.  
2. Configure any required settings in `autoUploader.txt` (e.g., credentials or upload settings).  
3. Run the script:
``` bash
  python PostBlog.py
```

4. The script will:
   - Scrape and parse the DOCX file into an Excel sheet.
   - Automatically upload the parsed data to the website.
   - Generate a detailed report in `report.xlsx`.

5. You can check the `report.xlsx` for any errors or issues with the parsing process.

---

## ğŸ” How It Works

- **PostBlog.py** is the main script that:
  - Reads the DOCX file and extracts relevant content.
  - Converts the content into an Excel file using **pandas**.
  - Automatically uploads the Excel data to the **Exampeer website** using configured credentials and settings.
  
- If there are errors, notification images (like `error.ico` and `error.jpg`) will be shown.

---

## âš ï¸ Disclaimer

This tool is intended for **internal business automation purposes** only and may not be suitable for general public use without modifications.  
Make sure to comply with your website's terms of service before automating any data scraping and uploading processes.

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ™‹â€â™‚ï¸ Author

Developed by @princemehta-git  
https://github.com/princemehta-git


